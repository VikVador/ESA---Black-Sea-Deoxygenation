{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a999b204-3b95-404f-93a1-90b1bda33abb",
   "metadata": {},
   "source": [
    "<img src=\"../assets/header_notebook.png\" />\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>ESA - Black Sea Deoxygenation Emulator</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55dcb8-9067-463c-b876-2e45565d6240",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# Librairies\n",
    "# ----------\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import dawgz\n",
    "import wandb\n",
    "import xarray\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dawgz (jobs //)\n",
    "from dawgz import job, schedule\n",
    "\n",
    "# -------------------\n",
    "# Librairies (Custom)\n",
    "# -------------------\n",
    "# Adding path to source folder to load custom modules\n",
    "sys.path.append('/src')\n",
    "sys.path.append('/src/debs/')\n",
    "sys.path.insert(1, '/src/debs/')\n",
    "sys.path.insert(1, '/scripts/')\n",
    "\n",
    "# Moving to the .py directory\n",
    "%cd src/debs/\n",
    "\n",
    "## Loading libraries\n",
    "from dataloader  import *\n",
    "from dataset     import *\n",
    "from losses      import *\n",
    "from metrics     import *\n",
    "from tools       import *\n",
    "from training    import *\n",
    "\n",
    "# -------\n",
    "# Jupyter\n",
    "# -------\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "# Making sure modules are reloaded when modified\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c007b-1cab-4407-a5f0-cbcdd836a569",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Scripts</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a neural network (using a given configuration)\n",
    "%run __training.py --config local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9aa051",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Dataloader</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98300e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import time\n",
    "import wandb\n",
    "import xarray\n",
    "import calendar\n",
    "import numpy as np\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "# Custom libraries\n",
    "from metrics                import *\n",
    "from tools                  import *\n",
    "from losses                 import *\n",
    "from dataset                import BlackSea_Dataset\n",
    "from dataloader             import BlackSea_Dataloader\n",
    "from neural_networks.loader import load_neural_network\n",
    "\n",
    "# -------------—---------\n",
    "#     Initialization\n",
    "# -------------—---------\n",
    "#\n",
    "# Information over terminal (1)\n",
    "project_title(kwargs)\n",
    "\n",
    "# Checking if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fixing random seed for reproducibility\n",
    "np.random.seed(2701)\n",
    "torch.manual_seed(2701)\n",
    "\n",
    "# Loading configuration\n",
    "project        = kwargs['Project']\n",
    "mode           = kwargs['Mode']\n",
    "window_input   = kwargs['Window (Inputs)']\n",
    "window_output  = kwargs['Window (Outputs)']\n",
    "frequencies    = kwargs['Frequencies']\n",
    "architecture   = kwargs['Architecture']\n",
    "learning_rate  = kwargs['Learning Rate']\n",
    "batch_size     = kwargs['Batch Size']\n",
    "nb_epochs      = kwargs['Epochs']\n",
    "num_workers    = kwargs['Number of Workers']\n",
    "\n",
    "# -------------—---------\n",
    "#     Loading the data\n",
    "# -----------------------\n",
    "validation = BlackSea_Dataset(\"Validation\")\n",
    "test       = BlackSea_Dataset(\"Test\")\n",
    "\n",
    "# Extracting the output (used by AverageNET)\n",
    "data_oxygen = validation.get_data(variable = \"oxygen\")\n",
    "\n",
    "# Loading the mesh, masks and bathymetry\n",
    "mesh                = test.get_mesh()\n",
    "bs_mask             = test.get_mask(continental_shelf = False)\n",
    "bs_mask_with_depth  = test.get_mask(continental_shelf = True)\n",
    "bathymetry          = test.get_depth(unit = \"meter\")\n",
    "\n",
    "# Hypoxia treshold\n",
    "hypox_tresh = test.get_treshold(standardized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "BS_loader_validation = BlackSea_Dataloader(validation,\n",
    "                                           window_input,\n",
    "                                           window_output,\n",
    "                                           frequencies,\n",
    "                                           batch_size,\n",
    "                                           num_workers,\n",
    "                                           mesh,\n",
    "                                           bs_mask,\n",
    "                                           bs_mask_with_depth,\n",
    "                                           bathymetry,\n",
    "                                           random = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea82c99",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Playground</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fe13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters definition\n",
    "kwargs = {\n",
    "    \"Project\"           : \"Test\",\n",
    "    \"Mode\"              : \"disabled\",\n",
    "    \"Window (Inputs)\"   : 1,\n",
    "    \"Window (Outputs)\"  : 10,\n",
    "    \"Frequencies\"       : 16,\n",
    "    \"Architecture\"      : \"UNET\",\n",
    "    \"Scaling\"           : 1,\n",
    "    \"Learning Rate\"     : 0.0001,\n",
    "    \"Batch Size\"        : 32,\n",
    "    \"Epochs\"            : 1,\n",
    "    'Number of Workers' : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c08286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import time\n",
    "import wandb\n",
    "import xarray\n",
    "import calendar\n",
    "import numpy as np\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "# Custom libraries\n",
    "from metrics                import *\n",
    "from tools                  import *\n",
    "from losses                 import *\n",
    "from dataset                import BlackSea_Dataset\n",
    "from dataloader             import BlackSea_Dataloader\n",
    "from neural_networks.loader import load_neural_network\n",
    "\n",
    "# -------------—---------\n",
    "#     Initialization\n",
    "# -------------—---------\n",
    "#\n",
    "# Information over terminal (1)\n",
    "project_title(kwargs)\n",
    "\n",
    "# Checking if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fixing random seed for reproducibility\n",
    "np.random.seed(2701)\n",
    "torch.manual_seed(2701)\n",
    "\n",
    "# Loading configuration\n",
    "project        = kwargs['Project']\n",
    "mode           = kwargs['Mode']\n",
    "window_input   = kwargs['Window (Inputs)']\n",
    "window_output  = kwargs['Window (Outputs)']\n",
    "frequencies    = kwargs['Frequencies']\n",
    "architecture   = kwargs['Architecture']\n",
    "learning_rate  = kwargs['Learning Rate']\n",
    "batch_size     = kwargs['Batch Size']\n",
    "nb_epochs      = kwargs['Epochs']\n",
    "num_workers    = kwargs['Number of Workers']\n",
    "\n",
    "# -------------—---------\n",
    "#     Loading the data\n",
    "# -----------------------\n",
    "validation = BlackSea_Dataset(\"Validation\")\n",
    "test       = BlackSea_Dataset(\"Test\")\n",
    "\n",
    "# Extracting the output (used by AverageNET)\n",
    "data_oxygen = validation.get_data(variable = \"oxygen\")\n",
    "\n",
    "# Loading the mesh, masks and bathymetry\n",
    "mesh                = test.get_mesh()\n",
    "bs_mask             = test.get_mask(continental_shelf = False)\n",
    "bs_mask_with_depth  = test.get_mask(continental_shelf = True)\n",
    "bathymetry          = test.get_depth(unit = \"meter\")\n",
    "\n",
    "# Hypoxia treshold\n",
    "hypox_tresh = test.get_treshold(standardized = True)\n",
    "\n",
    "# Data loaders\n",
    "BS_loader_validation = BlackSea_Dataloader(validation,\n",
    "                                           window_input,\n",
    "                                           window_output,\n",
    "                                           frequencies,\n",
    "                                           batch_size,\n",
    "                                           num_workers,\n",
    "                                           mesh,\n",
    "                                           bs_mask,\n",
    "                                           bs_mask_with_depth,\n",
    "                                           bathymetry,\n",
    "                                           random = True)\n",
    "\n",
    "BS_loader_test = BlackSea_Dataloader(test,\n",
    "                                     window_input,\n",
    "                                     window_output,\n",
    "                                     frequencies,\n",
    "                                     batch_size,\n",
    "                                     num_workers,\n",
    "                                     mesh,\n",
    "                                     bs_mask,\n",
    "                                     bs_mask_with_depth,\n",
    "                                     bathymetry,\n",
    "                                     random = True)\n",
    "\n",
    "# Creating the dataloaders\n",
    "dataset_validation   = BS_loader_validation.get_dataloader()\n",
    "dataset_test         = BS_loader_test.get_dataloader()\n",
    "\n",
    "# -------------—--------------------\n",
    "#     Neural Network & Training\n",
    "# -------------—--------------------\n",
    "# Initialization of the neural network\n",
    "neural_net = load_neural_network(architecture = architecture, data_output = data_oxygen, device = device, kwargs = kwargs)\n",
    "neural_net.to(device)\n",
    "\n",
    "# Total number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Available GPUs: \", num_gpus)\n",
    "\n",
    "# Total number of parameters\n",
    "nn_params = neural_net.count_parameters()\n",
    "print(\"Total number of parameters: \", nn_params/1e6, \"M\")\n",
    "\n",
    "# Using multiple GPUS\n",
    "neural_net = torch.nn.parallel.DataParallel(neural_net, device_ids=list(range(num_gpus)), dim=0)\n",
    "\n",
    "# Loading the optimizer\n",
    "optimizer  = optim.Adam(neural_net.parameters(), lr = learning_rate)\n",
    "\n",
    "# Loading the scheduler\n",
    "scheduler = LinearLR(optimizer, start_factor = 0.95, total_iters = nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB (1) - Initialization of the run\n",
    "wandb.init(project = project, mode = mode, config = kwargs)\n",
    "wandb.log({f\"Total number of parameters\": nn_params})\n",
    "\n",
    "# Used to compute the total time left,\n",
    "epoch_time = 0.0\n",
    "\n",
    "# ------- Training Loop -------\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "  # Timing the epoch (1)\n",
    "  start = time.time()\n",
    "\n",
    "  # Used to store and compute instantaneous training loss\n",
    "  loss_training_total, loss_training_per_day, loss_training_index = 0.0, list(), 0\n",
    "\n",
    "  # Training the neural network\n",
    "  for x, t, y in dataset_test:\n",
    "\n",
    "    # Pushing the data to the correct device\n",
    "    x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    pred = neural_net.forward(x, t)\n",
    "\n",
    "    # Computing the training loss\n",
    "    loss_training_batch_total, loss_training_batch_per_day = forecasting_loss(y_true = y,\n",
    "                                                                              y_pred = pred,\n",
    "                                                                                mask = bs_mask_with_depth)\n",
    "\n",
    "    # Accumulating the total loss, storing losses per day and updating the number of training steps\n",
    "    loss_training_total += loss_training_batch_total.item()\n",
    "    loss_training_index += 1\n",
    "    loss_training_per_day.append([l.item() for l in loss_training_batch_per_day])\n",
    "\n",
    "    print(\"Training Loss:\", loss_training_batch_total.item())\n",
    "\n",
    "    # AverageNet : No optimization needed !\n",
    "    if architecture == \"AVERAGE\":\n",
    "        continue\n",
    "\n",
    "    # Reseting the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss_training_batch_total.backward()\n",
    "\n",
    "    # Optimizing the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Freeing the GPU\n",
    "    x, y, t, pred = x.to(\"cpu\"), y.to(\"cpu\"), t.to(\"cpu\"), pred.to(\"cpu\")\n",
    "\n",
    "    # WandB (2.1) - Sending information about the training results\n",
    "    wandb.log({f\"Training/Loss (T)\": loss_training_batch_total.item()})\n",
    "    wandb.log({f\"Training/Loss (T, {i})\": loss.item() for i, loss in enumerate(loss_training_batch_per_day)})\n",
    "\n",
    "    # Freeing memory\n",
    "    del x, y, t, pred, loss_training_batch_total, loss_training_batch_per_day\n",
    "    break\n",
    "\n",
    "  # WandB (2.2) - Sending information about the training results\n",
    "  wandb.log({f\"Training/Loss (Training): \": loss_training_total / loss_training_index})\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    # Used to store and compute instantaneous training loss\n",
    "    loss_validation_total, loss_validation_per_day, loss_validation_index = 0.0, list(), 0\n",
    "\n",
    "    # Used to store all predictions and ground truth\n",
    "    validation_predictions, validation_ground_truth = None, None\n",
    "\n",
    "    # Used to store temporal information\n",
    "    time_days, time_months, time_years = list(), list(), list()\n",
    "\n",
    "    # Validating the neural network\n",
    "    for x, t, y in dataset_validation:\n",
    "\n",
    "      # Pushing the data to the correct device\n",
    "      x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      pred = neural_net.forward(x, t)\n",
    "\n",
    "      # Computing the validation loss\n",
    "      loss_validation_batch_total, loss_validation_batch_per_day = forecasting_loss(y_true = y,\n",
    "                                                                                    y_pred = pred,\n",
    "                                                                                      mask = bs_mask_with_depth)\n",
    "\n",
    "      # Accumulating the total loss, storing losses per day and updating the number of training steps\n",
    "      loss_validation_total += loss_validation_batch_total.item()\n",
    "      loss_validation_index += 1\n",
    "      loss_validation_per_day.append([l.item() for l in loss_validation_batch_per_day])\n",
    "\n",
    "      # Pushing everything back to the CPU\n",
    "      x, y, t, pred = x.to(\"cpu\"), y.to(\"cpu\"), t.to(\"cpu\"), pred.to(\"cpu\")\n",
    "\n",
    "      # WandB (3.1) - Sending information about the validation results\n",
    "      wandb.log({f\"Training/Loss (V)\": loss_validation_batch_total.item()})\n",
    "      wandb.log({f\"Training/Loss (V, {i})\": loss.item() for i, loss in enumerate(loss_validation_batch_per_day)})\n",
    "\n",
    "      print(\"Validation Loss:\", loss_validation_batch_total.item())\n",
    "\n",
    "      # Storing results\n",
    "      validation_predictions  = torch.cat((validation_predictions,  pred), dim = 0) if validation_predictions  is not None else pred\n",
    "      validation_ground_truth = torch.cat((validation_ground_truth,    y), dim = 0) if validation_ground_truth is not None else y\n",
    "\n",
    "      # Cleaning\n",
    "      del x, y, t, pred, loss_validation_batch_total, loss_validation_batch_per_day\n",
    "      torch.cuda.empty_cache()\n",
    "      break\n",
    "\n",
    "  # Updating the scheduler\n",
    "  scheduler.step()\n",
    "\n",
    "  # Timing the epoch (2)\n",
    "  epoch_time = (time.time() - start)/3600\n",
    "\n",
    "  # WandB (2.2) - Sending information about the training results\n",
    "  wandb.log({f\"Training/Loss (Validation): \": loss_validation_total / loss_validation_index,\n",
    "             f\"Training/Time Left (H)\": epoch_time})\n",
    "\n",
    "  # Computing the results\n",
    "  #analyze(validation_ground_truth, validation_predictions, bs_mask_with_depth, validation, BS_loader_validation)\n",
    "\n",
    "# Extracting the Neural Network back to CPU\n",
    "neural_net.to(\"cpu\")\n",
    "\n",
    "# Finishing the Weight and Biases run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esa",
   "language": "python",
   "name": "esa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
