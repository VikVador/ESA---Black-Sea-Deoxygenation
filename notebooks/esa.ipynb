{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a999b204-3b95-404f-93a1-90b1bda33abb",
   "metadata": {},
   "source": [
    "<img src=\"../assets/header_notebook.png\" />\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>ESA - Black Sea Deoxygenation Emulator</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b55dcb8-9067-463c-b876-2e45565d6240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "/Users/vikvador/Documents/ðŸš€ - European Space Agency (GIT)/ESA---Black-Sea-Deoxygenation/src/debs\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "# Librairies\n",
    "# ----------\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import dawgz\n",
    "import wandb\n",
    "import xarray\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dawgz (jobs //)\n",
    "from dawgz import job, schedule\n",
    "\n",
    "# -------------------\n",
    "# Librairies (Custom)\n",
    "# -------------------\n",
    "# Adding path to source folder to load custom modules\n",
    "sys.path.insert(1, '../src/debs/')\n",
    "sys.path.insert(1, '../scripts/')\n",
    "\n",
    "# Loading libraries\n",
    "from metrics              import *\n",
    "from tools                import *\n",
    "from dataset              import *\n",
    "from dataloader           import *\n",
    "\n",
    "# -------\n",
    "# Jupyter\n",
    "# -------\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "# Making sure modules are reloaded when modified\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Moving to the .py directory\n",
    "%cd ../src/debs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c007b-1cab-4407-a5f0-cbcdd836a569",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Scripts</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a neural network:\n",
    "%run training.py    --start_year                 0 \\\n",
    "                    --end_year                   0 \\\n",
    "                    --start_month                0 \\\n",
    "                    --end_month                  1 \\\n",
    "                    --inputs           temperature \\\n",
    "                    --problem       classification \\\n",
    "                    --windows_input              1 \\\n",
    "                    --windows_output             1 \\\n",
    "                    --depth                    200 \\\n",
    "                    --architecture         AVERAGE \\\n",
    "                    --scaling                    1 \\\n",
    "                    --loss_weights             1 1 \\\n",
    "                    --learning_rate          0.001 \\\n",
    "                    --batch_size                64 \\\n",
    "                    --epochs                     5 \\\n",
    "                    --kernel_size                3 \\\n",
    "                    --dawgz                  False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7aae61-7785-4d43-abbb-c3ad280f50e6",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Playground</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77694f02-1f69-444b-b479-89da86516e77",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------\n",
    "#    Parameters\n",
    "# -----------------\n",
    "#\n",
    "# Time window\n",
    "month_starting = 0\n",
    "month_ending   = 1\n",
    "year_starting  = 0\n",
    "year_ending    = 0\n",
    "\n",
    "# Maximum depth observed for oxygen, what is left is masked [m] (Note: To observe only the continental shelf set it to ~200m).\n",
    "depth_max_oxygen = 200\n",
    "\n",
    "# ------------------\n",
    "#  Loading the data\n",
    "# ------------------\n",
    "# Loading the different datasets\n",
    "Dataset_phy = BlackSea_Dataset(year_start  = year_starting,\n",
    "                               year_end    = year_ending,\n",
    "                               month_start = month_starting,\n",
    "                               month_end   = month_ending,\n",
    "                               variable    = \"grid_T\")\n",
    "\n",
    "Dataset_bio = BlackSea_Dataset(year_start  = year_starting,\n",
    "                               year_end    = year_ending,\n",
    "                               month_start = month_starting,\n",
    "                               month_end   = month_ending,\n",
    "                               variable    = \"ptrc_T\")\n",
    "\n",
    "# Loading the different field values\n",
    "data_temperature   = Dataset_phy.get_data(variable = \"temperature\", type = \"surface\", depth = None)\n",
    "data_salinity      = Dataset_phy.get_data(variable = \"salinity\",    type = \"surface\", depth = None)\n",
    "data_chlorophyll   = Dataset_bio.get_data(variable = \"chlorophyll\", type = \"surface\", depth = None)\n",
    "data_kshort        = Dataset_bio.get_data(variable = \"kshort\",      type = \"surface\", depth = None)\n",
    "data_klong         = Dataset_bio.get_data(variable = \"klong\",       type = \"surface\", depth = None)\n",
    "data_oxygen        = Dataset_bio.get_data(variable = \"oxygen\",      type = \"bottom\" , depth = depth_max_oxygen)\n",
    "\n",
    "# Loading the black sea masks\n",
    "bs_mask             = Dataset_phy.get_mask(depth = None)\n",
    "bs_mask_with_depth  = Dataset_phy.get_mask(depth = depth_max_oxygen)\n",
    "bs_mask_complete    = get_complete_mask(data_oxygen, bs_mask_with_depth)\n",
    "\n",
    "# --------------------\n",
    "#  Preparing the data\n",
    "# --------------------\n",
    "# Loading the dataloader\n",
    "BSD_loader = BlackSea_Dataloader(x = [data_temperature],\n",
    "                                 y = data_oxygen,\n",
    "                           bs_mask = bs_mask,\n",
    "                bs_mask_with_depth = bs_mask_with_depth,\n",
    "                              mode = \"regression\",\n",
    "                        window_inp = 1,\n",
    "                        window_out = 1)\n",
    "\n",
    "# Retrieving the datasets\n",
    "ds_validation = BSD_loader.get_dataloader(\"validation\")\n",
    "ds_train      = BSD_loader.get_dataloader(\"train\")\n",
    "ds_test       = BSD_loader.get_dataloader(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e5fdc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "#\n",
    "#        |\n",
    "#       / \\\n",
    "#      / _ \\                  ESA - PROJECT\n",
    "#     |.o '.|\n",
    "#     |'._.'|          BLACK SEA DEOXYGENATION EMULATOR\n",
    "#     |     |\n",
    "#   ,'|  |  |`.             BY VICTOR MANGELEER\n",
    "#  /  |  |  |  \\\n",
    "#  |,-'--|--'-.|                2023-2024\n",
    "#\n",
    "#\n",
    "# -------------------------------------------------------\n",
    "#\n",
    "# Documentation\n",
    "# -------------\n",
    "# A tool to load raw Black Sea datasets coming from the NEMO simulator (handles all kind of format for the file names).\n",
    "#\n",
    "import os\n",
    "import json\n",
    "import xarray\n",
    "import numpy as np\n",
    "from tools   import *\n",
    "\n",
    "\n",
    "class BlackSea_Dataset():\n",
    "    r\"\"\"A simple tool to load data of Black Sea simulations (NEMO Simulator) from 1980 to 2023.\"\"\"\n",
    "\n",
    "    def __init__(self, year_start: int = 1980,\n",
    "                         year_end: int = 1980,\n",
    "                      month_start: int = 1,\n",
    "                        month_end: int = 1,\n",
    "                           folder: str = \"output_HR001\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # Security (1)\n",
    "        assert year_start  in [i for i in range(1980, 2023)], f\"ERROR (Dataset, init) - Incorrect starting year ({year_start})\"\n",
    "        assert year_end    in [i for i in range(1980, 2023)], f\"ERROR (Dataset, init) - Incorrect ending year ({year_end})\"\n",
    "        assert month_start in [i for i in range(1, 13)],      f\"ERROR (Dataset, init) - Incorrect starting month ({month_start})\"\n",
    "        assert month_start in [i for i in range(1, 13)],      f\"ERROR (Dataset, init) - Incorrect ending month ({month_end})\"\n",
    "        assert year_start <= year_end,                        f\"ERROR (Dataset, init) - Incorrect years ({year_start} <= {year_end})\"\n",
    "\n",
    "        # Loading the name of all the useless variables, i.e. not usefull for our specific problem (for the sake of efficiency)\n",
    "        with open('../../information/useless.txt', 'r') as file:\n",
    "            self.useless_variables = json.load(file)\n",
    "\n",
    "        # Loading (all) the dictionnaries containing the path to each dataset, i.e. \"YEAR-MONTH : PATH(S)\"\n",
    "        with open('../../information/grid_T.txt', 'r') as file:\n",
    "            paths_physics_datasets_all = json.load(file)\n",
    "\n",
    "        with open('../../information/ptrc_T.txt', 'r') as file:\n",
    "            paths_biogeochemistry_datasets_all = json.load(file)\n",
    "\n",
    "        # Retrieving possible path to the folder containing the datasets\n",
    "        data_path_cluster, data_path_local = get_data_info()\n",
    "\n",
    "        # Path to the folder containing the data\n",
    "        self.datasets_folder = data_path_cluster + f\"{folder}/\" if os.path.exists(data_path_cluster) else \\\n",
    "                               data_path_local   + f\"{folder}/\"\n",
    "\n",
    "        # Stores all the relevant paths datasets\n",
    "        self.paths_physics_datasets, self.paths_biogeochemistry_datasets = list(), list()\n",
    "\n",
    "        # Extraction\n",
    "        for year in range(year_start, year_end + 1):\n",
    "            for month in range(month_start, month_end + 1):\n",
    "\n",
    "                # Converting to strings\n",
    "                year  = str(year)\n",
    "                month = f\"0{month}\" if month < 10 else str(month)\n",
    "\n",
    "                # Creation of the key\n",
    "                key = f\"{year}-{month}\"\n",
    "\n",
    "                # Retreiving the paths\n",
    "                self.paths_physics_datasets         += [self.datasets_folder + p for p in paths_physics_datasets_all[key]]\n",
    "                self.paths_biogeochemistry_datasets += [self.datasets_folder + p for p in paths_biogeochemistry_datasets_all[key]]\n",
    "\n",
    "        # Saving other relevant information\n",
    "        self.month_start = month_start\n",
    "        self.month_end   = month_end\n",
    "        self.year_end    = year_end\n",
    "        self.year_start  = year_start\n",
    "        self.folder      = folder\n",
    "\n",
    "    def get_mesh(self, x: int, y: int):\n",
    "        r\"\"\"Used to retrieve a mesh with normalized coordinates for the given shape (x, y)\"\"\"\n",
    "\n",
    "        # Creation of the mesh\n",
    "        x_mesh, y_mesh = np.meshgrid(np.linspace(0, 1, num = x), np.linspace(0, 1, num = y), indexing = 'ij')\n",
    "\n",
    "        # Concatenation of the mesh (np.float32 is the type needed for torch when converted afterforwards)\n",
    "        return np.stack((x_mesh, y_mesh), axis = 0, dtype = np.float32)\n",
    "\n",
    "    def get_depth(self, unit: str):\n",
    "        \"\"\"Used to retrieve the maximum depths position (indexes in 3D data) or the maximum depths values (in meters)\"\"\"\n",
    "\n",
    "        # Security\n",
    "        assert unit in [\"index\", \"meter\"], f\"ERROR (get_depths), Incorrect type ({unit})\"\n",
    "\n",
    "        # Path to the mesh file location\n",
    "        path_mesh = get_mesh_path()\n",
    "\n",
    "        # Loading the information in the correct shape\n",
    "        return xarray.open_dataset(path_mesh, engine = \"h5netcdf\").bathy_metry.data.astype('float32') if unit == \"meter\" else \\\n",
    "               xarray.open_dataset(path_mesh, engine = \"h5netcdf\").mbathy.data\n",
    "\n",
    "    def get_mask(self, depth: int = None):\n",
    "        r\"\"\"Used to retreive a mask of the Black Sea, i.e. 0 if land, 1 if the Black Sea. If depth is given, it will also set to 0 all regions below that depth\"\"\"\n",
    "\n",
    "        # Retrieving possible path to the data\n",
    "        mask_path_cluster, mask_path_local, mask_name = get_mask_info()\n",
    "\n",
    "        # Loading the dataset containing information about the Black Sea mesh\n",
    "        mesh_data = xarray.open_dataset(mask_path_cluster + mask_name if os.path.exists(mask_path_cluster) else \\\n",
    "                                        mask_path_local   + mask_name,\n",
    "                                        engine = \"h5netcdf\")\n",
    "\n",
    "        # Loading the complete Black sea mask\n",
    "        bs_mask = mesh_data.tmask[0, 0].data\n",
    "\n",
    "        # Checks if we want to hide regions below a given depth\n",
    "        if not depth == None:\n",
    "\n",
    "            # Retreives the bottom depth in [m] for each pixel\n",
    "            depth_values = mesh_data.bathy_metry.data[0]\n",
    "\n",
    "            # Remove all information for regions located below the given depth\n",
    "            bs_mask[depth <= depth_values] = 0\n",
    "\n",
    "        # Returning the processed mask\n",
    "        return bs_mask\n",
    "\n",
    "    def get_data(self, variable: str,\n",
    "                          level: int = None,\n",
    "                         region: str = None,\n",
    "                          depth: int = None):\n",
    "        r\"\"\"Used to retreive the data for a given variable at a specific level or a specific region\"\"\"\n",
    "\n",
    "        # Security (1)\n",
    "        assert variable in [\"temperature\", \"salinity\", \"oxygen\", \"chlorophyll\", \"kshort\", \"klong\"], f\"ERROR (get_data), Incorrect variable ({variable})\"\n",
    "        assert level  == None or (0 <= level and level < 59),                                       f\"ERROR (get_data), Incorrect level (0 < {level} < 59)\"\n",
    "        assert region == None or region in [\"surface\", \"bottom\", \"all\"],                            f\"ERROR (get_data), Incorrect region ({region})\"\n",
    "\n",
    "        # Security (2) - Choosing between level or region\n",
    "        assert not (level == None and region == None), f\"ERROR (get_data), You must specify either a level or a region\"\n",
    "        assert not (level != None and region != None), f\"ERROR (get_data), You must specify either a level or a region, not both\"\n",
    "\n",
    "        def translate(variable: str):\n",
    "            r\"\"\"Used to translate a variable into its name in the dataset, retrieve the type of dataset and the useless variables (the other ones)\"\"\"\n",
    "\n",
    "            # Stores the translations for all the EO variables and oxygen\n",
    "            translations = {\"temperature\" : [\"votemper\", \"physics\"],\n",
    "                            \"salinity\"    : [\"vosaline\", \"physics\"],\n",
    "                            \"oxygen\"      : [\"DOX\",      \"biogeochemistry\"],\n",
    "                            \"chlorophyll\" : [\"CHL\",      \"biogeochemistry\"],\n",
    "                            \"kshort\"      : [\"KBIOS\",    \"biogeochemistry\"],\n",
    "                            \"klong\"       : [\"KBIOL\",    \"biogeochemistry\"]}\n",
    "\n",
    "            # Retrieving translation\n",
    "            v, v_type = translations[variable]\n",
    "\n",
    "            # Returns also the useless variables\n",
    "            return v, v_type, [values[0] for key, values in translations.items() if key != variable]\n",
    "\n",
    "        def get_bottom(data: np.array, depth = None):\n",
    "            r\"\"\"Used to retreive the data profile (2D) everywhere at the bottom of the Black Sea (None) of for all regions above a given depth\"\"\"\n",
    "\n",
    "            # Security\n",
    "            assert len(data.shape) == 4, f\"ERROR (get_bottom), Incorrect data shape ({data.shape}), i.e. input dimensions should be (time, depth, y, x)\"\n",
    "\n",
    "            # Retreiving the bathymetry mask b(t, x, y) = z_bottom, i.e. index at which we found bottom of the sea\n",
    "            bathy_mask = self.get_bathymetry()\n",
    "\n",
    "            # Creation of x and y indexes to make manipulation\n",
    "            x, y = np.arange(bathy_mask.shape[2]), np.arange(bathy_mask.shape[1])\n",
    "            xidx = x.reshape(-1,1).repeat(len(y), axis = 1).T\n",
    "            yidx = y.reshape(-1,1).repeat(len(x), axis = 1)\n",
    "\n",
    "            # Retreiving the data everywhere at the bottom\n",
    "            data = data[:, bathy_mask[0] - 1, yidx, xidx]\n",
    "\n",
    "            # Hiding the regions below the given depth\n",
    "            if not depth == None:\n",
    "                data[:, self.get_mask(depth = depth) == 0] = np.nan\n",
    "\n",
    "            return data\n",
    "\n",
    "        # Translation\n",
    "        variable, variable_type, other_useless_variables = translate(variable)\n",
    "\n",
    "        # Loading the data (3D field)\n",
    "        data = xarray.open_mfdataset(self.paths_physics_datasets if variable_type == \"physics\" else \\\n",
    "                                     self.paths_biogeochemistry_datasets,\n",
    "                                     engine         = \"h5netcdf\",\n",
    "                                     parallel       = True,\n",
    "                                     drop_variables = self.useless_variables + other_useless_variables)\n",
    "\n",
    "        # Level, i.e. selecting a specific depth by its index\n",
    "        if not level == None:\n",
    "            return data[variable][:, level, :, :].data.compute()\n",
    "\n",
    "        # All (3D)\n",
    "        if region == \"all\":\n",
    "            return data[variable][:, :, :, :].data.compute()\n",
    "\n",
    "        # Surface (2D)\n",
    "        if region == \"surface\":\n",
    "            return data[variable][:, 0, :, :].data.compute()\n",
    "\n",
    "        # Bottom (2D)\n",
    "        if region == \"bottom\":\n",
    "            return get_bottom(data[variable].data.compute(), depth = depth)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
