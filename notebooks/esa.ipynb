{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a999b204-3b95-404f-93a1-90b1bda33abb",
   "metadata": {},
   "source": [
    "<img src=\"../assets/header_notebook.png\" />\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>ESA - Black Sea Deoxygenation Emulator</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55dcb8-9067-463c-b876-2e45565d6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "# Librairies\n",
    "# ----------\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import dawgz\n",
    "import wandb\n",
    "import xarray\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dawgz (jobs //)\n",
    "from dawgz import job, schedule\n",
    "\n",
    "# -------------------\n",
    "# Librairies (Custom)\n",
    "# -------------------\n",
    "# Adding path to source folder to load custom modules\n",
    "sys.path.append('/src')\n",
    "sys.path.append('/src/debs/')\n",
    "sys.path.insert(1, '/src/debs/')\n",
    "sys.path.insert(1, '/scripts/')\n",
    "\n",
    "# Moving to the .py directory\n",
    "%cd src/debs/\n",
    "\n",
    "## Loading libraries\n",
    "from metrics     import *\n",
    "from dataset     import *\n",
    "from dataloader  import *\n",
    "from tools       import *\n",
    "from losses      import *\n",
    "\n",
    "# -------\n",
    "# Jupyter\n",
    "# -------\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "# Making sure modules are reloaded when modified\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c007b-1cab-4407-a5f0-cbcdd836a569",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Scripts</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the preprocessed data (normalized)\n",
    "%run __generate_n.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a98d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the preprocessed data (standardized)\n",
    "%run __generate_s.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the data distributions\n",
    "%run __distributions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23f012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "                                                       \n",
      "                    ESA - PROJECT                      \n",
      "                                                       \n",
      "          BLACK SEA DEOXYGENATION EMULATOR             \n",
      "                                                       \n",
      "-------------------------------------------------------\n",
      "                                                       \n",
      "- Project : ESA - Black Sea Deoxygenation Emulator - Test 2 (Local)\n",
      "- Month (Starting) : 6\n",
      "- Month (Ending) : 9\n",
      "- Year (Starting) : 1980\n",
      "- Year (Ending) : 1980\n",
      "- Hypoxia Treshold : 63\n",
      "- Depth : 150\n",
      "- Inputs : ['temperature', 'salinity', 'chlorophyll', 'kshort', 'klong']\n",
      "- Window (Inputs) : 14\n",
      "- Window (Output) : 1\n",
      "- Window (Transformation) : 1\n",
      "- Architecture : UNET\n",
      "- Scaling : 8\n",
      "- Kernel Size : 3\n",
      "- Datasets Size : [0.6, 0.3]\n",
      "- Loss Weights : [1, 1]\n",
      "- Learning Rate : 0.001\n",
      "- Batch Size : 16\n",
      "- Epochs : 10\n",
      "\n",
      "-----------------\n",
      "Emulator Training\n",
      "-----------------\n",
      "Number of trainable parameters:  9847118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/gpfs/home/acad/ulg-mast/vmangele/ESA---Black-Sea-Deoxygenation/src/debs/wandb/run-20240409_195338-xwbn44xr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vmangeleer/ESA%20-%20Black%20Sea%20Deoxygenation%20Emulator%20-%20Test%202%20%28Local%29/runs/xwbn44xr' target=\"_blank\">sunny-silence-1</a></strong> to <a href='https://wandb.ai/vmangeleer/ESA%20-%20Black%20Sea%20Deoxygenation%20Emulator%20-%20Test%202%20%28Local%29' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vmangeleer/ESA%20-%20Black%20Sea%20Deoxygenation%20Emulator%20-%20Test%202%20%28Local%29' target=\"_blank\">https://wandb.ai/vmangeleer/ESA%20-%20Black%20Sea%20Deoxygenation%20Emulator%20-%20Test%202%20%28Local%29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vmangeleer/ESA%20-%20Black%20Sea%20Deoxygenation%20Emulator%20-%20Test%202%20%28Local%29/runs/xwbn44xr' target=\"_blank\">https://wandb.ai/vmangeleer/ESA%20-%20Black%20Sea%20Deoxygenation%20Emulator%20-%20Test%202%20%28Local%29/runs/xwbn44xr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training a neural network (using a given configuration)\n",
    "%run __training.py --config local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ebd86a",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Data</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb72cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the different inputs\n",
    "BSD_dataset = BlackSea_Dataset(year_start  = 2020,\n",
    "                               year_end    = 2021,\n",
    "                               month_start = 1,\n",
    "                               month_end   = 12)\n",
    "\n",
    "data_temperature   = BSD_dataset.get_data(variable = \"temperature\")\n",
    "data_salinity      = BSD_dataset.get_data(variable = \"salinity\")\n",
    "data_chlorophyll   = BSD_dataset.get_data(variable = \"chlorophyll\")\n",
    "data_kshort        = BSD_dataset.get_data(variable = \"kshort\")\n",
    "data_klong         = BSD_dataset.get_data(variable = \"klong\")\n",
    "data_oxygen        = BSD_dataset.get_data(variable = \"oxygen\")\n",
    "mask               = BSD_dataset.get_mask(False)\n",
    "maskCS             = BSD_dataset.get_mask(True)\n",
    "\n",
    "def generate_animation(data : np.array, mask : np.array, title : str, limits : list = [0, 1]):\n",
    "    \"\"\"Generate an animation of the data, i.e. used to inspect the data\"\"\"\n",
    "    import os\n",
    "    import cv2\n",
    "    import imageio\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    from matplotlib.patches import Rectangle\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Converting to booleans for easier plot\n",
    "    mask = mask > 0.5\n",
    "\n",
    "    # Displaying information over terminal\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "    def index_to_date(i):\n",
    "        \"\"\"Used to convert an index to a date, i.e. useful for the title of the plot\"\"\"\n",
    "\n",
    "        # Define the start date\n",
    "        start_date = datetime(2020, 1, 1)\n",
    "\n",
    "        # Calculate the offset from the start date\n",
    "        delta = timedelta(days=i)\n",
    "\n",
    "        # Calculate the corresponding date\n",
    "        result_date = start_date + delta\n",
    "\n",
    "        # Format the date as a string in the \"YYYY-MM-DD\" format\n",
    "        return result_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Creation of a folder if it does not exist\n",
    "    if not os.path.exists(f'../../analysis/images/{title}'):\n",
    "        os.mkdir(f'../../analysis/images/{title}/')\n",
    "\n",
    "    # Displaying information over terminal\n",
    "    print(f\"Generating images for {title}...\")\n",
    "\n",
    "    # Creating of the plots\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.figure(figsize = (12, 8))\n",
    "        plt.imshow(data[i], cmap='viridis', vmin = limits[0], vmax = limits[1])\n",
    "        plt.colorbar(fraction = 0.021)\n",
    "        plt.imshow(mask, cmap='gray', alpha=0.025)\n",
    "        date_string = index_to_date(i)\n",
    "        ax = plt.gca()\n",
    "        box = Rectangle((0.85, 0.9), 0.46, 0.16, edgecolor='black', facecolor='black', transform=ax.transAxes)\n",
    "        plt.annotate(date_string, xy=(0.98, 0.96), xycoords='axes fraction',\n",
    "                    horizontalalignment='right', verticalalignment='top',\n",
    "                    fontsize=12, color='white')\n",
    "        ax.add_patch(box)\n",
    "        plt.grid(True, alpha=0.1)\n",
    "        plt.savefig(f'../../analysis/images/{title}/{title}_{i}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Displaying information over terminal\n",
    "    print(\"Loading images...\")\n",
    "\n",
    "    # Creation of the paths and opening the plots\n",
    "    paths = [f\"../../analysis/images/{title}/{title}_{i}.png\" for i in range(data.shape[0])]\n",
    "    image_array = []\n",
    "    for my_file in paths:\n",
    "        image = Image.open(my_file)\n",
    "        image_array.append(image)\n",
    "\n",
    "    # Displaying information over terminal\n",
    "    print(\"Generating the video...\")\n",
    "\n",
    "    # Generating the video\n",
    "    with imageio.get_writer(f'../../analysis/images/{title}.gif', mode='I') as writer:\n",
    "        for filename in paths:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "# Generating the animations\n",
    "generate_animation(data_oxygen,      maskCS,      \"oxygen\", limits = [0, 1])\n",
    "generate_animation(data_temperature,   mask, \"temperature\", limits = [0, 1])\n",
    "generate_animation(data_salinity,      mask,    \"salinity\", limits = [0, 1])\n",
    "generate_animation(data_chlorophyll,   mask, \"chlorophyll\", limits = [0, 0.25])\n",
    "generate_animation(data_kshort,        mask,      \"kshort\", limits = [0, 0.1])\n",
    "generate_animation(data_klong,         mask,       \"klong\", limits = [0, 0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the different inputs\n",
    "BSD_dataset = BlackSea_Dataset(year_start  = 2010,\n",
    "                               year_end    = 2020,\n",
    "                               month_start = 1,\n",
    "                               month_end   = 12)\n",
    "\n",
    "data_oxygen        = BSD_dataset.get_data(variable = \"oxygen\")\n",
    "mask               = BSD_dataset.get_mask(False)\n",
    "maskCS             = BSD_dataset.get_mask(True)\n",
    "\n",
    "# Extracting the training set\n",
    "training_set = data_oxygen[: 365 * 6]\n",
    "\n",
    "# Computing the mean\n",
    "mean_6years = np.mean(training_set, axis = 0)\n",
    "\n",
    "# Stores the mean each year\n",
    "mean_each_year = [np.mean(data_oxygen[i * 365 : (i + 1) * 365], axis = 0) for i in range(6)]\n",
    "\n",
    "def save_plot(data : np.array, mask : np.array, title : str):\n",
    "    \"\"\"Save the plot of the mean\"\"\"\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.imshow(data, cmap='viridis', vmin = 0, vmax = 1)\n",
    "    plt.colorbar(fraction = 0.021)\n",
    "    plt.imshow(mask, cmap='gray', alpha = 0.025)\n",
    "    date_string = f\"Mean : {title}\"\n",
    "    ax = plt.gca()\n",
    "    box = Rectangle((0.80, 0.90), 0.56, 0.16, edgecolor='black', facecolor='black', transform=ax.transAxes)\n",
    "    plt.annotate(date_string, xy=(0.98, 0.965), xycoords='axes fraction',\n",
    "                horizontalalignment='right', verticalalignment='top',\n",
    "                fontsize=12, color='white')\n",
    "    ax.add_patch(box)\n",
    "    plt.grid(True, alpha=0.1)\n",
    "    plt.savefig(f'../../analysis/means/means_{title}.png')\n",
    "\n",
    "# Saving the plot for all the years\n",
    "save_plot(mean_6years, maskCS, \"Training\")\n",
    "\n",
    "# Saving the plot for each year\n",
    "for i, n in enumerate([\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"]):\n",
    "    save_plot(mean_each_year[i], maskCS, n)\n",
    "\n",
    "# Normalized deoxygenation treshold\n",
    "hypox_tresh = xarray.open_dataset(BSD_dataset.paths[0])[\"HYPON\"].data.item()\n",
    "\n",
    "# Computing the average state of the region (Hypoxia or not)\n",
    "mean_6years_state = mean_6years < hypox_tresh\n",
    "\n",
    "# Stores the mean each year\n",
    "mean_each_year_state = [mean < hypox_tresh for mean in mean_each_year]\n",
    "\n",
    "def save_plot_state(data : np.array, mask : np.array, title : str):\n",
    "    \"\"\"Save the plot of the mean\"\"\"\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.imshow(data, cmap='viridis', vmin = 0, vmax = 1)\n",
    "    cbar = plt.colorbar(fraction=0.021)\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.set_ticklabels(['Oxygenated', 'Hypoxia'])\n",
    "    plt.imshow(mask, cmap='gray', alpha = 0.25)\n",
    "    date_string = f\"Mean : {title}\"\n",
    "    ax = plt.gca()\n",
    "    box = Rectangle((0.80, 0.90), 0.56, 0.16, edgecolor='black', facecolor='black', transform=ax.transAxes)\n",
    "    plt.annotate(date_string, xy=(0.98, 0.965), xycoords='axes fraction',\n",
    "                horizontalalignment='right', verticalalignment='top',\n",
    "                fontsize=12, color='white')\n",
    "    ax.add_patch(box)\n",
    "    plt.grid(True, alpha=0.1)\n",
    "    plt.savefig(f'../../analysis/means/means_{title}.png')\n",
    "\n",
    "# Saving the plot for all the years\n",
    "save_plot_state(mean_6years_state, maskCS, \"Training (H)\")\n",
    "\n",
    "# Saving the plot for each year\n",
    "for i, n in enumerate([\"2010 (H)\", \"2011 (H)\", \"2012 (H)\", \"2013 (H)\", \"2014 (H)\", \"2015 (H)\"]):\n",
    "    save_plot_state(mean_each_year_state[i], maskCS, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending everything to wandb\n",
    "wandb.init(project = \"ESA - Repport\")\n",
    "\n",
    "# Sending the animations\n",
    "wandb.log({\"Oxygen\":              wandb.Video(\"../../analysis/images/oxygen.gif\", fps = 1),\n",
    "           \"Temperature\":         wandb.Video(\"../../analysis/images/temperature.gif\", fps = 1),\n",
    "           \"Salinity\":            wandb.Video(\"../../analysis/images/salinity.gif\", fps = 1),\n",
    "           \"Chlorophyll\":         wandb.Video(\"../../analysis/images/chlorophyll.gif\", fps = 1),\n",
    "           \"Reflectance (Short)\": wandb.Video(\"../../analysis/images/kshort.gif\", fps = 1),\n",
    "           \"Reflectance (Long)\" : wandb.Video(\"../../analysis/images/klong.gif\", fps = 1)})\n",
    "\n",
    "# Sending the mean concentrations\n",
    "wandb.log({\"Concentration (Mean, 2010-2015)\": wandb.Image(f\"../../analysis/means/means_Training.png\"),\n",
    "           \"Concentration (Mean, 2010)\":      wandb.Image(f\"../../analysis/means/means_2010.png\"),\n",
    "           \"Concentration (Mean, 2011)\":      wandb.Image(f\"../../analysis/means/means_2011.png\"),\n",
    "           \"Concentration (Mean, 2012)\":      wandb.Image(f\"../../analysis/means/means_2012.png\"),\n",
    "           \"Concentration (Mean, 2013)\":      wandb.Image(f\"../../analysis/means/means_2013.png\"),\n",
    "           \"Concentration (Mean, 2014)\":      wandb.Image(f\"../../analysis/means/means_2014.png\"),\n",
    "           \"Concentration (Mean, 2015)\":      wandb.Image(f\"../../analysis/means/means_2015.png\")})\n",
    "\n",
    "# Sending the mean states\n",
    "wandb.log({\"State (Mean, 2010-2015)\": wandb.Image(f\"../../analysis/means/means_Training_(H).png\"),\n",
    "           \"State (Mean, 2010)\":      wandb.Image(f\"../../analysis/means/means_2010_(H).png\"),\n",
    "           \"State (Mean, 2011)\":      wandb.Image(f\"../../analysis/means/means_2011_(H).png\"),\n",
    "           \"State (Mean, 2012)\":      wandb.Image(f\"../../analysis/means/means_2012_(H).png\"),\n",
    "           \"State (Mean, 2013)\":      wandb.Image(f\"../../analysis/means/means_2013_(H).png\"),\n",
    "           \"State (Mean, 2014)\":      wandb.Image(f\"../../analysis/means/means_2014_(H).png\"),\n",
    "           \"State (Mean, 2015)\":      wandb.Image(f\"../../analysis/means/means_2015_(H).png\")})\n",
    "\n",
    "# Closing the wandb session\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9aa051",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Playground</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6356ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "#    Parameters\n",
    "# -----------------\n",
    "#\n",
    "# Time window\n",
    "month_starting = 6\n",
    "month_ending   = 8\n",
    "year_starting  = 1980\n",
    "year_ending    = 1980\n",
    "\n",
    "# Window size\n",
    "windows_inputs = 1\n",
    "\n",
    "# ------------------\n",
    "#  Loading the data\n",
    "# ------------------\n",
    "# Loading the different datasets\n",
    "BSD_dataset = BlackSea_Dataset(year_start  = year_starting,\n",
    "                               year_end    = year_ending,\n",
    "                               month_start = month_starting,\n",
    "                               month_end   = month_ending)\n",
    "\n",
    "# Loading the days ID (used to give temporal information to the model)\n",
    "days_ID = BSD_dataset.get_days()\n",
    "\n",
    "# Loading the different inputs\n",
    "data_temperature   = BSD_dataset.get_data(variable = \"temperature\")\n",
    "data_salinity      = BSD_dataset.get_data(variable = \"salinity\")\n",
    "data_chlorophyll   = BSD_dataset.get_data(variable = \"chlorophyll\")\n",
    "data_kshort        = BSD_dataset.get_data(variable = \"kshort\")\n",
    "data_klong         = BSD_dataset.get_data(variable = \"klong\")\n",
    "\n",
    "# Loading the output\n",
    "data_oxygen = BSD_dataset.get_data(variable = \"oxygen\")\n",
    "\n",
    "# Loading spatial information\n",
    "bathy = BSD_dataset.get_depth(unit = \"meter\")\n",
    "mesh  = BSD_dataset.get_mesh(x = 256, y = 576)\n",
    "\n",
    "# Hypoxia treshold\n",
    "hypox_tresh = xarray.open_dataset(BSD_dataset.paths[0])[\"HYPON\"].data.item()\n",
    "\n",
    "# Loading the black sea masks\n",
    "bs_mask             = BSD_dataset.get_mask(continental_shelf = False)\n",
    "bs_mask_with_depth  = BSD_dataset.get_mask(continental_shelf = True)\n",
    "bs_mask_complete    = get_complete_mask(data_oxygen, hypox_tresh, bs_mask_with_depth)\n",
    "\n",
    "# Creation of the dataloader\n",
    "BSD_loader = BlackSea_Dataloader(x = [data_temperature, data_salinity, data_chlorophyll, data_kshort, data_klong],\n",
    "                                 y = data_oxygen,\n",
    "                                 t = days_ID,\n",
    "                              mesh = mesh,\n",
    "                              mask = bs_mask,\n",
    "                        bathymetry = bathy,\n",
    "                        window_inp = windows_inputs)\n",
    "\n",
    "# Retrieving the datasets\n",
    "ds_train      = BSD_loader.get_dataloader(\"train\")\n",
    "ds_validation = BSD_loader.get_dataloader(\"validation\")\n",
    "ds_test       = BSD_loader.get_dataloader(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "#\n",
    "#        |\n",
    "#       / \\\n",
    "#      / _ \\                  ESA - PROJECT\n",
    "#     |.o '.|\n",
    "#     |'._.'|          BLACK SEA DEOXYGENATION EMULATOR\n",
    "#     |     |\n",
    "#   ,'|  |  |`.             BY VICTOR MANGELEER\n",
    "#  /  |  |  |  \\\n",
    "#  |,-'--|--'-.|                2023-2024\n",
    "#\n",
    "#\n",
    "# -------------------------------------------------------\n",
    "#\n",
    "# Documentation\n",
    "# -------------\n",
    "# A neural network definition to be used as temporal encoder\n",
    "#\n",
    "# Pytorch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FCNN(nn.Sequential):\n",
    "    r\"\"\"A fully convolutional neural network\"\"\"\n",
    "\n",
    "    def __init__(self, inputs: int, kernel_size : int = 3, scaling : int = 1):\n",
    "        super(FCNN, self).__init__()\n",
    "\n",
    "        # Initialization (predicting mean and standard deviation)\n",
    "        self.n_in    = inputs\n",
    "        self.n_out   = 2\n",
    "        self.padding = kernel_size // 2\n",
    "\n",
    "        # ------ Architecture ------\n",
    "        #\n",
    "        # Main Layers\n",
    "        self.conv_init           = nn.Conv2d(self.n_in    , 256 * scaling, kernel_size, padding = self.padding)\n",
    "        self.conv_intermediate_1 = nn.Conv2d(256 * scaling, 128 * scaling, kernel_size, padding = self.padding)\n",
    "        self.conv_intermediate_2 = nn.Conv2d(128 * scaling,  64 * scaling, kernel_size, padding = self.padding)\n",
    "        self.conv_intermediate_3 = nn.Conv2d( 64 * scaling,  32 * scaling, kernel_size, padding = self.padding)\n",
    "        self.conv_final          = nn.Conv2d( 32 * scaling,    self.n_out, kernel_size, padding = self.padding)\n",
    "\n",
    "        # Activation function\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "        # Normalization\n",
    "        self.normalization_init           = nn.BatchNorm2d(self.conv_init.out_channels)\n",
    "        self.normalization_intermediate_1 = nn.BatchNorm2d(self.conv_intermediate_1.out_channels)\n",
    "        self.normalization_intermediate_2 = nn.BatchNorm2d(self.conv_intermediate_2.out_channels)\n",
    "        self.normalization_intermediate_3 = nn.BatchNorm2d(self.conv_intermediate_3.out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Forward pass\n",
    "        x = self.normalization_init(self.activation(self.conv_init(x)))\n",
    "        x = self.normalization_intermediate_1(self.activation(self.conv_intermediate_1(x)))\n",
    "        x = self.normalization_intermediate_2(self.activation(self.conv_intermediate_2(x)))\n",
    "        x = self.normalization_intermediate_3(self.activation(self.conv_intermediate_3(x)))\n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        # Retrieiving dimensions (Ease of comprehension)\n",
    "        b, c, x_res, y_res = x.shape\n",
    "\n",
    "        # Reshaping the output, i.e. (samples, days, values, x, y)\n",
    "        return x.reshape(b, self.n_out // 2, 2, x_res, y_res)\n",
    "\n",
    "    def count_parameters(self,):\n",
    "        r\"\"\"Determines the number of trainable parameters in the model\"\"\"\n",
    "        return int(sum(p.numel() for p in self.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76799521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network stuff\n",
    "neural_network = FCNN(inputs  = 184,\n",
    "                      kernel_size = 5,\n",
    "                      scaling = 3)\n",
    "\n",
    "optimizer = optim.Adam(neural_network.parameters(), lr = 0.001)\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "neural_network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "show = True\n",
    "\n",
    "for epoch in range(15):\n",
    "\n",
    "    metrics_tool = BlackSea_Metrics(mode = \"regression\",\n",
    "                                    mask = bs_mask_with_depth,\n",
    "                           mask_complete = bs_mask_complete,\n",
    "                                treshold = norm_oxy,\n",
    "                       number_of_samples = BSD_loader.get_number_of_samples(\"validation\"))\n",
    "\n",
    "    for x, y in ds_train:\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        prediction = neural_network(x)\n",
    "        loss_training = compute_loss(y_pred = prediction, y_true = y, mask = bs_mask_with_depth, problem = \"regression\", device = \"cpu\", kwargs = {})\n",
    "        print(f\"E{epoch} - Loss (Training):\", loss_training.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss_training.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Cleaning\n",
    "        del x, y, prediction, loss_training\n",
    "        torch.cuda.empty_cache()\n",
    "        break\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Stores all the predictions for the metrics (plots)\n",
    "        prediction_all = None\n",
    "\n",
    "        for x, y in ds_validation:\n",
    "\n",
    "            # Making prediction\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            prediction = neural_network(x)\n",
    "            loss_validation = compute_loss(y_pred = prediction, y_true = y, mask = bs_mask_with_depth, problem = \"regression\", device = \"cpu\", kwargs = {})\n",
    "            print(f\"E{epoch} - Loss (Validation):\", loss_validation.item())\n",
    "            x, y, prediction = x.to(\"cpu\"), y.to(\"cpu\"), prediction.to(\"cpu\")\n",
    "\n",
    "\n",
    "            # Plotting mean against ground truth in a subplot\n",
    "            if show:\n",
    "\n",
    "                # Highlighting hypoxic areas\n",
    "                y_hyp = ( y          < norm_oxy ) * 1.0\n",
    "                p_hyp = ( prediction < norm_oxy ) * 1.0\n",
    "\n",
    "                # Hiding non-obserable areas\n",
    "                p_hyp[:,:,:, bs_mask_with_depth == 0] = torch.nan\n",
    "                y_hyp[:,:,:, bs_mask_with_depth == 0] = torch.nan\n",
    "\n",
    "\n",
    "                plt.figure(figsize = (20, 20))\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(y_hyp[0, 0, 0])\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(p_hyp[0, 0, 0])\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.imshow(y_hyp[0, 0, 0] - p_hyp[0, 0, 0])\n",
    "                plt.setp(plt.gcf().get_axes(), xticks = [], yticks = [])\n",
    "                plt.subplot(1, 3, 1).set_title(\"Ground Truth\", fontsize = 6)\n",
    "                plt.subplot(1, 3, 2).set_title(\"Prediction\", fontsize = 6)\n",
    "                plt.subplot(1, 3, 3).set_title(\"Difference\", fontsize = 6)\n",
    "                plt.show()\n",
    "\n",
    "                prediction[:,:,:, bs_mask_with_depth == 0] = torch.nan\n",
    "                y[:,:,:, bs_mask_with_depth == 0]          = torch.nan\n",
    "\n",
    "                plt.figure(figsize = (20, 20))\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(y[0, 0, 0])\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(prediction[0, 0, 0])\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.imshow(torch.exp(prediction[0, 0, 1]/2))\n",
    "                plt.setp(plt.gcf().get_axes(), xticks = [], yticks = [])\n",
    "                plt.subplot(1, 3, 1).set_title(\"Ground Truth\", fontsize = 6)\n",
    "                plt.subplot(1, 3, 2).set_title(\"Prediction (Mean)\", fontsize = 6)\n",
    "                plt.subplot(1, 3, 3).set_title(\"Prediction (Std)\", fontsize = 6)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            # Concatenating all the predictions\n",
    "            prediction_all = torch.cat((prediction_all, prediction), dim = 0) if prediction_all is not None else prediction\n",
    "\n",
    "            del x, y, prediction\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            break\n",
    "\n",
    "    \"\"\"\n",
    "    # Sampling random data for comparison\n",
    "    # Metrics\n",
    "    y_vall_all = torch.from_numpy(BSD_loader.y_validation)\n",
    "    #metrics_tool.compute_metrics(y_pred = prediction_all, y_true = y_vall_all)\n",
    "    metrics_tool.compute_plots_comparison_regression(y_pred = prediction_all, y_true = y_vall_all)\n",
    "\n",
    "\n",
    "    #metrics_tool.compute_plots(  y_pred = prediction_all, y_true = y_vall_all)\n",
    "\n",
    "    # Getting the results\n",
    "    if show:\n",
    "        results, results_name = metrics_tool.get_results()\n",
    "        for r, n in zip(results[0], results_name):\n",
    "            print(n, \" : \", r)\n",
    "        print(\"\\n\")\n",
    "    \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esa",
   "language": "python",
   "name": "esa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
