{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a999b204-3b95-404f-93a1-90b1bda33abb",
   "metadata": {},
   "source": [
    "<img src=\"../assets/header_notebook.png\" />\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>ESA - Black Sea Deoxygenation Emulator</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b55dcb8-9067-463c-b876-2e45565d6240",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdawgz\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "# Librairies\n",
    "# ----------\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import dawgz\n",
    "import wandb\n",
    "import xarray\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dawgz (jobs //)\n",
    "from dawgz import job, schedule\n",
    "\n",
    "# -------------------\n",
    "# Librairies (Custom)\n",
    "# -------------------\n",
    "# Adding path to source folder to load custom modules\n",
    "sys.path.append('/src')\n",
    "sys.path.append('/src/debs/')\n",
    "sys.path.insert(1, '/src/debs/')\n",
    "sys.path.insert(1, '/scripts/')\n",
    "\n",
    "# Moving to the .py directory\n",
    "%cd src/debs/\n",
    "\n",
    "## Loading libraries\n",
    "from dataloader  import *\n",
    "from dataset     import *\n",
    "from losses      import *\n",
    "from metrics     import *\n",
    "from tools       import *\n",
    "from training    import *\n",
    "\n",
    "# -------\n",
    "# Jupyter\n",
    "# -------\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "# Making sure modules are reloaded when modified\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c007b-1cab-4407-a5f0-cbcdd836a569",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Scripts</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a neural network (using a given configuration)\n",
    "%run __training.py --config local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea82c99",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>Playground</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fe13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters definition\n",
    "kwargs = {\n",
    "    \"Project\"             : \"Evaluation\",\n",
    "    \"Mode\"                : \"online\",\n",
    "    \"Window (Inputs)\"     : 1,\n",
    "    \"Window (Outputs)\"    : 3,\n",
    "    \"Frequencies\"         : 256,\n",
    "    \"Number of Gaussians\" : 1,\n",
    "    \"Architecture\"        : \"UNET\",\n",
    "    \"Scaling\"             : 4,\n",
    "    \"Learning Rate\"       : 0.0005,\n",
    "    \"Batch Size\"          : 32,\n",
    "    \"Epochs\"              : 10,\n",
    "    'Number of Workers'   : 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c08286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import time\n",
    "import wandb\n",
    "import xarray\n",
    "import calendar\n",
    "import numpy as np\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "# Custom libraries\n",
    "from metrics                import *\n",
    "from tools                  import *\n",
    "from losses                 import *\n",
    "from dataset                import BlackSea_Dataset\n",
    "from dataloader             import BlackSea_Dataloader\n",
    "from neural_networks.loader import load_neural_network\n",
    "\n",
    "# -------------—---------\n",
    "#     Initialization\n",
    "# -------------—---------\n",
    "#\n",
    "# Information over terminal (1)\n",
    "project_title(kwargs)\n",
    "\n",
    "# Checking if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fixing random seed for reproducibility\n",
    "np.random.seed(2701)\n",
    "torch.manual_seed(2701)\n",
    "\n",
    "# Loading configuration\n",
    "project        = kwargs['Project']\n",
    "mode           = kwargs['Mode']\n",
    "window_input   = kwargs['Window (Inputs)']\n",
    "window_output  = kwargs['Window (Outputs)']\n",
    "frequencies    = kwargs['Frequencies']\n",
    "architecture   = kwargs['Architecture']\n",
    "learning_rate  = kwargs['Learning Rate']\n",
    "batch_size     = kwargs['Batch Size']\n",
    "nb_epochs      = kwargs['Epochs']\n",
    "num_workers    = kwargs['Number of Workers']\n",
    "\n",
    "# -------------—---------\n",
    "#     Loading the data\n",
    "# -----------------------\n",
    "validation = BlackSea_Dataset(\"Validation\")\n",
    "test       = BlackSea_Dataset(\"Test\")\n",
    "\n",
    "# Extracting the output (used by AverageNET)\n",
    "data_oxygen = validation.get_data(variable = \"oxygen\")\n",
    "\n",
    "# Loading the mesh, masks and bathymetry\n",
    "mesh                = test.get_mesh()\n",
    "bs_mask             = test.get_mask(continental_shelf = False)\n",
    "bs_mask_with_depth  = test.get_mask(continental_shelf = True)\n",
    "bathymetry          = test.get_depth(unit = \"meter\")\n",
    "\n",
    "# Hypoxia treshold\n",
    "hypox_tresh = test.get_treshold(standardized = True)\n",
    "\n",
    "# Data loaders\n",
    "BS_loader_validation = BlackSea_Dataloader(validation,\n",
    "                                           window_input,\n",
    "                                           window_output,\n",
    "                                           frequencies,\n",
    "                                           batch_size,\n",
    "                                           num_workers,\n",
    "                                           mesh,\n",
    "                                           bs_mask,\n",
    "                                           bs_mask_with_depth,\n",
    "                                           bathymetry,\n",
    "                                           random = False)\n",
    "\n",
    "BS_loader_test = BlackSea_Dataloader(test,\n",
    "                                     window_input,\n",
    "                                     window_output,\n",
    "                                     frequencies,\n",
    "                                     batch_size,\n",
    "                                     num_workers,\n",
    "                                     mesh,\n",
    "                                     bs_mask,\n",
    "                                     bs_mask_with_depth,\n",
    "                                     bathymetry,\n",
    "                                     random = True)\n",
    "\n",
    "# Creating the dataloaders\n",
    "dataset_validation   = BS_loader_validation.get_dataloader()\n",
    "dataset_test         = BS_loader_test.get_dataloader()\n",
    "\n",
    "# -------------—--------------------\n",
    "#     Neural Network & Training\n",
    "# -------------—--------------------\n",
    "# Initialization of the neural network\n",
    "neural_net = load_neural_network(architecture = architecture, data_output = data_oxygen, device = device, kwargs = kwargs)\n",
    "neural_net.to(device)\n",
    "\n",
    "# Total number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Available GPUs: \", num_gpus)\n",
    "\n",
    "# Total number of parameters\n",
    "nn_params = neural_net.count_parameters()\n",
    "print(\"Total number of parameters: \", nn_params/1e6, \"M\")\n",
    "\n",
    "# Using multiple GPUS\n",
    "neural_net = torch.nn.parallel.DataParallel(neural_net, device_ids=list(range(num_gpus)), dim=0)\n",
    "\n",
    "# Loading the optimizer\n",
    "optimizer  = optim.Adam(neural_net.parameters(), lr = learning_rate)\n",
    "\n",
    "# Loading the scheduler\n",
    "scheduler = LinearLR(optimizer, start_factor = 0.95, total_iters = nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, t, y in dataset_test:\n",
    "    print(x.shape, t.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB (1) - Initialization of the run\n",
    "wandb.init(project = project, mode = mode, config = kwargs)\n",
    "wandb.log({f\"Total number of parameters\": nn_params})\n",
    "\n",
    "# Used to compute the total time left,\n",
    "epoch_time = 0.0\n",
    "\n",
    "# ------- Training Loop -------\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "  # Timing the epoch (1)\n",
    "  start = time.time()\n",
    "\n",
    "  # Used to store and compute instantaneous training loss\n",
    "  loss_training_total, loss_training_per_day, loss_training_index = 0.0, list(), 0\n",
    "\n",
    "  # Used to compute metrics\n",
    "  metrics = BlackSea_Metrics(data_oxygen = data_oxygen, mask = bs_mask_with_depth, hypoxia_treshold = hypox_tresh, window_output = window_output, number_trajectories = 25)\n",
    "\n",
    "  # Indexes\n",
    "  i_t = 0\n",
    "  i_v = 0\n",
    "\n",
    "  # Training the neural network\n",
    "  for x, t, y in dataset_test:\n",
    "\n",
    "    # Pushing the data to the correct device\n",
    "    x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    pred = neural_net.forward(x, t)\n",
    "\n",
    "    # Computing the training loss\n",
    "    loss_training_batch_total, loss_training_batch_per_day = forecasting_loss(y_true = y,\n",
    "                                                                              y_pred = pred,\n",
    "                                                                                mask = bs_mask_with_depth)\n",
    "\n",
    "    # Accumulating the total loss, storing losses per day and updating the number of training steps\n",
    "    loss_training_total += loss_training_batch_total.item()\n",
    "    loss_training_index += 1\n",
    "    loss_training_per_day.append([l.item() for l in loss_training_batch_per_day])\n",
    "\n",
    "    print(\"Training Loss:\", loss_training_batch_total.item())\n",
    "\n",
    "    # AverageNet : No optimization needed !\n",
    "    if architecture == \"AVERAGE\":\n",
    "        continue\n",
    "\n",
    "    # Reseting the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss_training_batch_total.backward()\n",
    "\n",
    "    # Optimizing the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Freeing the GPU\n",
    "    x, y, t, pred = x.to(\"cpu\"), y.to(\"cpu\"), t.to(\"cpu\"), pred.to(\"cpu\")\n",
    "\n",
    "    # WandB (2.1) - Sending information about the training results\n",
    "    wandb.log({f\"Training/Loss (T)\": loss_training_batch_total.item()})\n",
    "    wandb.log({f\"Training/Loss (T, {i})\": loss.item() for i, loss in enumerate(loss_training_batch_per_day)})\n",
    "\n",
    "    # Freeing memory\n",
    "    del x, y, t, pred, loss_training_batch_total, loss_training_batch_per_day\n",
    "\n",
    "    if i_t == 1:\n",
    "        break\n",
    "    else:\n",
    "        i_t += 1\n",
    "\n",
    "  # WandB (2.2) - Sending information about the training results\n",
    "  wandb.log({f\"Training/Loss (Training): \": loss_training_total / loss_training_index})\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    # Used to store and compute instantaneous training loss\n",
    "    loss_validation_total, loss_validation_per_day, loss_validation_index = 0.0, list(), 0\n",
    "\n",
    "    # Used to store temporal information\n",
    "    time_days, time_months, time_years = list(), list(), list()\n",
    "\n",
    "    # Validating the neural network\n",
    "    for x, t, y in dataset_validation:\n",
    "\n",
    "      # Pushing the data to the correct device\n",
    "      x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      pred = neural_net.forward(x, t)\n",
    "\n",
    "      # Computing the validation loss\n",
    "      loss_validation_batch_total, loss_validation_batch_per_day = forecasting_loss(y_true = y,\n",
    "                                                                                    y_pred = pred,\n",
    "                                                                                      mask = bs_mask_with_depth)\n",
    "\n",
    "      # Accumulating the total loss, storing losses per day and updating the number of training steps\n",
    "      loss_validation_total += loss_validation_batch_total.item()\n",
    "      loss_validation_index += 1\n",
    "      loss_validation_per_day.append([l.item() for l in loss_validation_batch_per_day])\n",
    "\n",
    "      # Pushing everything back to the CPU\n",
    "      x, y, t, pred = x.to(\"cpu\"), y.to(\"cpu\"), t.to(\"cpu\"), pred.to(\"cpu\")\n",
    "\n",
    "      # WandB (3.1) - Sending information about the validation results\n",
    "      wandb.log({f\"Training/Loss (V)\": loss_validation_batch_total.item()})\n",
    "      wandb.log({f\"Training/Loss (V, {i})\": loss.item() for i, loss in enumerate(loss_validation_batch_per_day)})\n",
    "\n",
    "      # Information over terminal\n",
    "      print(\"Validation Loss:\", loss_validation_batch_total.item())\n",
    "\n",
    "      # Computing metrics\n",
    "      metrics.analyze(pred, y)\n",
    "\n",
    "      # Cleaning\n",
    "      del x, y, t, pred, loss_validation_batch_total, loss_validation_batch_per_day\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      if i_v == 1:\n",
    "        break\n",
    "      else:\n",
    "        i_v += 1\n",
    "\n",
    "  # Updating the scheduler\n",
    "  scheduler.step()\n",
    "\n",
    "  # Timing the epoch (2)\n",
    "  epoch_time = (nb_epochs - epoch) * ((time.time() - start)/3600)\n",
    "\n",
    "  # WandB (2.2) - Sending information about the training results\n",
    "  wandb.log({f\"Training/Loss (Validation): \": loss_validation_total / loss_validation_index,\n",
    "             f\"Training/Time Left (H)\": epoch_time})\n",
    "\n",
    "  # Sending the results\n",
    "  metrics.send_results()\n",
    "\n",
    "# Extracting the Neural Network back to CPU\n",
    "# neural_net.to(\"cpu\")\n",
    "\n",
    "# Finishing the Weight and Biases run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackSea_Metrics():\n",
    "   r\"\"\"A tool to create a dataloader that processes and loads the Black Sea datasets on the fly\"\"\"\n",
    "\n",
    "   def __init__(self, data_oxygen: np.array, mask: np.array, hypoxia_treshold: float, window_output: int = 10, number_trajectories: int = 10, number_samples: int = 1461):\n",
    "      r\"\"\"Initialization of the metrics helper tool\"\"\"\n",
    "\n",
    "      # Storing useful information\n",
    "      self.index                        = 0\n",
    "      self.mask                         = torch.from_numpy(mask)\n",
    "      self.window_output                = window_output\n",
    "      self.number_samples               = number_samples\n",
    "      self.hypoxia_treshold             = hypoxia_treshold\n",
    "      self.number_trajectories          = number_trajectories\n",
    "      self.data_oxygen_temporal_average = torch.from_numpy(np.mean(data_oxygen[365:(1826 - window_output)], axis = 0))\n",
    "\n",
    "      # Storing regression metrics results\n",
    "      self.bias        = None\n",
    "      self.mae         = None\n",
    "      self.rmse        = None\n",
    "      self.r2_spatial  = None\n",
    "      self.r2_temporal = None\n",
    "\n",
    "      # Storing classification metrics results\n",
    "      self.acc  = None\n",
    "      self.pre  = None\n",
    "      self.rec  = None\n",
    "\n",
    "   def analyze(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "      \"\"\"Used to analyze the predictions of the neural network by computing different metrics\"\"\"\n",
    "\n",
    "      def generate_trajectories(y_pred: torch.Tensor, number_trajectories: int):\n",
    "         \"\"\"Used to generate trajectories from the neural network means, standard deviations and coefficients\"\"\"\n",
    "\n",
    "         # Extracting dimensions\n",
    "         batch_size, forecasted_days, number_gaussians, values, x_res, y_res = y_pred.shape\n",
    "\n",
    "         # ----- Deterministic Trajectories -----\n",
    "         if number_gaussians == 1:\n",
    "               return y_pred[:, :, :, 0].clone()\n",
    "\n",
    "         # ----- Stochastic Trajectories -----\n",
    "         #\n",
    "         # Extracting values\n",
    "         mean, std, pi = y_pred[:, :, :, 0], torch.exp(y_pred[:, :, :, 1]/2), torch.nn.functional.softmax(y_pred[:, :, :, 2], dim = 2)\n",
    "\n",
    "         # Reshaping to apply multinomial\n",
    "         mean = rearrange(mean, 'b d n x y -> (b d x y) n')\n",
    "         std  = rearrange(std,  'b d n x y -> (b d x y) n')\n",
    "         pi   = rearrange(pi,   'b d n x y -> (b d x y) n')\n",
    "\n",
    "         # Sampling the coefficients\n",
    "         coefficients = torch.multinomial(input = pi, num_samples = number_trajectories, replacement = True)\n",
    "\n",
    "         # Extracting the mean and standard deviation of each trajectory\n",
    "         mean = mean.gather(1, coefficients)\n",
    "         std  = std.gather(1, coefficients)\n",
    "\n",
    "         # Sampling the trajectories\n",
    "         trajectories = torch.normal(mean, std)\n",
    "\n",
    "         # Reshaping the trajectories\n",
    "         return rearrange(trajectories, '(b d x y) n -> b d n x y', b = batch_size, d = forecasted_days, n = number_trajectories, x = x_res, y = y_res)\n",
    "\n",
    "      def compute_percentiles(metric: torch.Tensor):\n",
    "         \"\"\"Used to compute the percentiles (10% and 90%) as well as the median across realizations for given metric results\"\"\"\n",
    "         return rearrange(torch.quantile(metric, torch.tensor([0.10, 0.5, 0.90]), dim = 2), 'n b d -> b d n')\n",
    "\n",
    "      def vizualize_trajectories(trajectories: torch.Tensor, y_true: torch.Tensor, mask: torch.Tensor, index: int):\n",
    "         \"\"\"Used to vizualize different generated the trajectories\"\"\"\n",
    "\n",
    "         # -------------------------\n",
    "         #    Deterministic Model\n",
    "         # -------------------------\n",
    "         #\n",
    "         # Only one trajectory because its the mean\n",
    "         if trajectories.shape[2] == 1:\n",
    "\n",
    "             # Extracting trajectories\n",
    "            visualized_trajectory = trajectories[0, 0, 0].detach().numpy()\n",
    "            visualized_true         = y_true[0, 0].detach().numpy()\n",
    "\n",
    "            # Masking the values\n",
    "            visualized_trajectory[mask[0] == 0] = np.nan\n",
    "            visualized_true[mask[0] == 0]       = np.nan\n",
    "\n",
    "            # Extracting region of interest\n",
    "            visualized_trajectory = visualized_trajectory[25:125, 70:270]\n",
    "            visualized_true       = visualized_true[25:125, 70:270]\n",
    "\n",
    "            # Defining minimum and maximum values\n",
    "            vmin, vmax = np.nanmin(visualized_true), np.nanmax(visualized_true)\n",
    "\n",
    "            # Creation of the Plot\n",
    "            fig, axes = plt.subplots(1, 2, figsize = (15, 6))\n",
    "            im = axes[0].imshow(visualized_true, cmap = \"viridis\", vmin=vmin, vmax=vmax)\n",
    "            axes[0].set_title(\"Ground Truth\", fontsize = 10)\n",
    "            axes[0].axis('off')\n",
    "            im = axes[1].imshow(visualized_trajectory, cmap = \"viridis\", vmin=vmin, vmax=vmax)\n",
    "            axes[1].set_title(\"Prediction (Mean)\", fontsize = 10)\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            # Add a colorbar to the ground truth plot\n",
    "            cbar = fig.colorbar(im, ax=axes[1], fraction = 0.026, pad = 0.04)\n",
    "\n",
    "            # Sending results to WandB\n",
    "            wandb.log({f\"Observing Trajectories (Mean)/Sample ({index})\": wandb.Image(fig)})\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "         # -------------------------\n",
    "         #     Generative Model\n",
    "         # -------------------------\n",
    "         #\n",
    "         else:\n",
    "\n",
    "            # Extracting trajectories\n",
    "            visualized_trajectories = trajectories[0, 0, :10].detach().numpy()\n",
    "            visualized_true         = y_true[0, 0].detach().numpy()\n",
    "\n",
    "            # Masking the values\n",
    "            visualized_trajectories[:, mask[0] == 0] = np.nan\n",
    "            visualized_true[mask[0] == 0]         = np.nan\n",
    "\n",
    "            # Extracting region of interest\n",
    "            visualized_trajectories = visualized_trajectories[:, 25:125, 70:270]\n",
    "            visualized_true         = visualized_true[25:125, 70:270]\n",
    "\n",
    "            # Defining minimum and maximum values\n",
    "            vmin, vmax = np.nanmin(visualized_true), np.nanmax(visualized_true)\n",
    "\n",
    "            # Create a figure with 3 rows and 5 columns\n",
    "            fig, axes = plt.subplots(3, 4, figsize = (15, 6))\n",
    "\n",
    "            # Plot the ground truth in the top-left corner\n",
    "            im = axes[0, 0].imshow(visualized_true, cmap = \"viridis\", vmin=vmin, vmax=vmax)\n",
    "            axes[0, 0].set_title(\"Ground Truth\", fontsize = 10)\n",
    "            axes[0, 0].axis('off')\n",
    "\n",
    "            # Add a colorbar to the ground truth plot\n",
    "            cbar = fig.colorbar(im, ax=axes[0, 0], fraction = 0.026, pad = 0.04)\n",
    "\n",
    "            # Hide the rest of the plots in the first row\n",
    "            for i in range(1, 4):\n",
    "               axes[0, i].axis('off')\n",
    "\n",
    "            # Plot the predicted trajectories in the next two rows\n",
    "            for i in range(8):\n",
    "               row = i // 4 + 1\n",
    "               col = i % 4\n",
    "               axes[row, col].imshow(visualized_trajectories[i], cmap = \"viridis\", vmin=vmin, vmax=vmax)\n",
    "               axes[row, col].axis('off')\n",
    "\n",
    "            # Sending results to WandB\n",
    "            wandb.log({f\"Observing Trajectories/Sample ({index})\": wandb.Image(fig)})\n",
    "            plt.close()\n",
    "\n",
    "      # Generating the trajectories\n",
    "      trajectories = generate_trajectories(y_pred, self.number_trajectories)\n",
    "\n",
    "      # Visualizing the trajectories on WandB\n",
    "      vizualize_trajectories(trajectories, y_true, self.mask, self.index)\n",
    "\n",
    "      # Updating the index (used to name the different samples)\n",
    "      self.index += 1\n",
    "\n",
    "      # Masking useless values\n",
    "      trajectories = trajectories[:, :, :, self.mask[0] == 1]\n",
    "      y_true       = y_true[:, :, self.mask[0] == 1]\n",
    "\n",
    "      # Adding dimensions to make broadcasting possible\n",
    "      y_true = y_true[:, :, None, :].expand(-1, -1, trajectories.shape[2], -1)\n",
    "\n",
    "      # computing the oxygen temporal and spatial average\n",
    "      data_oxygen_temporal_average = self.data_oxygen_temporal_average[None, None, None, self.mask[0] == 1].expand(trajectories.shape)\n",
    "      data_oxygen_spatial_average  = torch.nanmean(y_true, axis = 3, keepdim = True).expand(trajectories.shape)\n",
    "\n",
    "      # -------------------------\n",
    "      #    Metrics Regression\n",
    "      # -------------------------\n",
    "      #\n",
    "      # Computing the different metrics\n",
    "      metric_MAE  = torch.nanmean(torch.absolute(y_true - trajectories),          axis = 3)\n",
    "      metric_BIAS = torch.nanmean((y_true - trajectories)/torch.absolute(y_true), axis = 3) * 100\n",
    "      metric_RMSE = torch.sqrt(torch.nanmean((y_true - trajectories) ** 2,        axis = 3))\n",
    "\n",
    "      # Computing the R2 scores spatially and temporally\n",
    "      metric_R2_NUMERATOR = torch.sum((y_true - trajectories) ** 2, axis = 3)\n",
    "      metric_R2_TEMPORAL  = 1 - metric_R2_NUMERATOR / torch.sum((y_true - data_oxygen_temporal_average) ** 2, axis = 3)\n",
    "      metric_R2_SPATIAL   = 1 - metric_R2_NUMERATOR / torch.sum((y_true - data_oxygen_spatial_average)  ** 2, axis = 3)\n",
    "\n",
    "      # Computing the quantiles and updating the metrics\n",
    "      self.mae         = compute_percentiles(metric_MAE)         if self.mae is None         else torch.cat((self.mae,         compute_percentiles(metric_MAE)),         dim = 0)\n",
    "      self.bias        = compute_percentiles(metric_BIAS)        if self.bias is None        else torch.cat((self.bias,        compute_percentiles(metric_BIAS)),        dim = 0)\n",
    "      self.rmse        = compute_percentiles(metric_RMSE)        if self.rmse is None        else torch.cat((self.rmse,        compute_percentiles(metric_RMSE)),        dim = 0)\n",
    "      self.r2_spatial  = compute_percentiles(metric_R2_SPATIAL)  if self.r2_spatial is None  else torch.cat((self.r2_spatial,  compute_percentiles(metric_R2_SPATIAL)),  dim = 0)\n",
    "      self.r2_temporal = compute_percentiles(metric_R2_TEMPORAL) if self.r2_temporal is None else torch.cat((self.r2_temporal, compute_percentiles(metric_R2_TEMPORAL)), dim = 0)\n",
    "\n",
    "      # ----------------------------\n",
    "      #    Metrics Classification\n",
    "      # ----------------------------\n",
    "      #\n",
    "      # Detecting Hypoxia\n",
    "      trajectories = (trajectories < self.hypoxia_treshold) * 1\n",
    "      y_true       = (y_true       < self.hypoxia_treshold) * 1\n",
    "\n",
    "      # Calculate True Positives (TP), False Positives (FP), True Negatives (TN), False Negatives (FN)\n",
    "      TP = torch.sum(y_true * trajectories,             dim = 3)\n",
    "      FP = torch.sum((1 - y_true) * trajectories,       dim = 3)\n",
    "      TN = torch.sum((1 - y_true) * (1 - trajectories), dim = 3)\n",
    "      FN = torch.sum(y_true * (1 - trajectories),       dim = 3)\n",
    "\n",
    "      # Computing the metrics\n",
    "      metric_ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "      metric_PRE = TP / (TP + FP)\n",
    "      metric_REC = TP / (TP + FN)\n",
    "\n",
    "      # Computing the quantiles and updating the metrics\n",
    "      self.acc = compute_percentiles(metric_ACC) if self.acc is None else torch.cat((self.acc, compute_percentiles(metric_ACC)), dim = 0)\n",
    "      self.pre = compute_percentiles(metric_PRE) if self.pre is None else torch.cat((self.pre, compute_percentiles(metric_PRE)), dim = 0)\n",
    "      self.rec = compute_percentiles(metric_REC) if self.rec is None else torch.cat((self.rec, compute_percentiles(metric_REC)), dim = 0)\n",
    "\n",
    "   def send_results(self):\n",
    "\n",
    "      def metric_global(data: torch.Tensor, name: str):\n",
    "         \"\"\"Used to compute a global metric, i.e., average over samples and then forecast\"\"\"\n",
    "\n",
    "         # Computing the global metric\n",
    "         global_metric = torch.nanmean(data, axis = (0, 1))\n",
    "\n",
    "         # Storing results for WandB\n",
    "         return {f\"Global Metrics/{name} (10%)\":  global_metric[0],\n",
    "                 f\"Global Metrics/{name} (50%)\":  global_metric[1],\n",
    "                 f\"Global Metrics/{name} (90%)\":  global_metric[2]}\n",
    "\n",
    "      def metric_forecast(data: torch.Tensor, name: str):\n",
    "         \"\"\"Used to compute a forecast metric, i.e., average over samples\"\"\"\n",
    "\n",
    "         # Computing the forecast metric\n",
    "         forecast_metric = torch.nanmean(data, axis = (0))\n",
    "\n",
    "         # Stores the complete dictionary of results\n",
    "         forecast_results = {}\n",
    "\n",
    "         # Computing results for each day\n",
    "         for f, results in enumerate(forecast_metric):\n",
    "            forecast_results[f\"Forecast Metrics/{name} - Day \" + str(f) + \" (10%)\"] = results[0]\n",
    "            forecast_results[f\"Forecast Metrics/{name} - Day \" + str(f) + \" (50%)\"] = results[1]\n",
    "            forecast_results[f\"Forecast Metrics/{name} - Day \" + str(f) + \" (90%)\"] = results[2]\n",
    "\n",
    "         return forecast_results\n",
    "\n",
    "      def metric_forecast_evolution(data: torch.Tensor, limits: list, name: str):\n",
    "         \"\"\"Used to display the evolution of a metric over time for a single, i.e. the validation\"\"\"\n",
    "\n",
    "         # Conversion to numpy\n",
    "         data = data.detach().numpy()\n",
    "\n",
    "         # Retrieving dimensions for ease of use\n",
    "         number_days, forecasted_days, values = data.shape\n",
    "\n",
    "         # -------------------------------\n",
    "         #   Plots For Individual Model\n",
    "         # -------------------------------\n",
    "         #\n",
    "         # Due to WandB restriction, by sending a plot, we can display evolution\n",
    "         # over epochs but cannot plot model results against one another\n",
    "         #\n",
    "         # Looping over different limits\n",
    "         for i, l in enumerate(limits):\n",
    "\n",
    "            # Plotting the evolution of the metric\n",
    "            fig = plt.figure(figsize = (15, 5))\n",
    "\n",
    "            # Showing the best (first day), worst (last day) forecast\n",
    "            plt.plot(data[:,  0,  0],  color = \"#00ffff\", linestyle = \"dotted\", label = f'($T_{0}$) Q10%')\n",
    "            plt.plot(data[:,  0,  1],  color = \"#00ffff\", linestyle = \"solid\",  label = f'($T_{0}$) Median')\n",
    "            plt.plot(data[:,  0,  2],  color = \"#00ffff\", linestyle = \"dashed\", label = f'($T_{0}$) Q90%')\n",
    "            plt.plot(data[:,  -1,  0], color = \"#004c6d\", linestyle = \"dotted\", label = f'($T_{forecasted_days - 1}$) Q10%')\n",
    "            plt.plot(data[:,  -1,  1], color = \"#004c6d\", linestyle = \"solid\",  label = f'($T_{forecasted_days - 1}$) Median')\n",
    "            plt.plot(data[:,  -1,  2], color = \"#004c6d\", linestyle = \"dashed\", label = f'($T_{forecasted_days - 1}$) Q90%')\n",
    "            plt.grid(alpha = 0.5)\n",
    "            plt.xlabel(\"Days\")\n",
    "            plt.ylabel(name)\n",
    "            plt.ylim(l)\n",
    "            plt.legend(loc = 'upper right', bbox_to_anchor=(1.01, 1.15), ncol = 6)\n",
    "\n",
    "            # Sending to WandB\n",
    "            wandb.log({f\"Forecast Metrics Evolution/{name} ({i})\": wandb.Image(fig)})\n",
    "            plt.close()\n",
    "\n",
    "         # -------------------------------\n",
    "         #   Comparison Plot For Models\n",
    "         # -------------------------------\n",
    "         #\n",
    "         # Days on the x-axis\n",
    "         x_axis = np.arange(number_days)\n",
    "\n",
    "         # Logging the results\n",
    "         wandb.log({f\"Forecast Metrics Evolution (Comparison)/{name} ($T_{0}$)\" : wandb.plot.line_series(\n",
    "                                    xs = x_axis,\n",
    "                                    ys = [data[:, 0, 0], data[:, 0, 1], data[:, 0, 2]],\n",
    "                                  keys = [\"Q10%\", \"Median\", \"Q90%\"],\n",
    "                                 title = f\"{name} - T0\",\n",
    "                                 xname = \"Days\"),\n",
    "                     f\"Forecast Metrics Evolution (Comparison)/{name} ($T_{forecasted_days - 1}$)\" : wandb.plot.line_series(\n",
    "                                    xs = x_axis,\n",
    "                                    ys = [data[:, -1, 0], data[:, -1, 1], data[:, -1, 2]],\n",
    "                                  keys = [\"Q10%\", \"Median\", \"Q90%\"],\n",
    "                                 title = f\"{name} - T{forecasted_days - 1}\",\n",
    "                                 xname = \"Days\")})\n",
    "\n",
    "      # Global - Give a rough idea of the performance\n",
    "      wandb.log(metric_global(self.mae,         \"Mean Absolute Error\"))\n",
    "      wandb.log(metric_global(self.bias,        \"Percent Bias\"))\n",
    "      wandb.log(metric_global(self.rmse,        \"Root Mean Square Error\"))\n",
    "      wandb.log(metric_global(self.r2_spatial,  \"Coefficient of Determination R2 - Spatial\"))\n",
    "      wandb.log(metric_global(self.r2_temporal, \"Coefficient of Determination R2 - Temporal\"))\n",
    "      wandb.log(metric_global(self.acc,         \"Accuracy\"))\n",
    "      wandb.log(metric_global(self.pre,         \"Precision\"))\n",
    "      wandb.log(metric_global(self.rec,         \"Recall\"))\n",
    "\n",
    "      # Forecast - Give a rough idea of the performance for each forecasted days\n",
    "      wandb.log(metric_forecast(self.mae,         \"Mean Absolute Error\"))\n",
    "      wandb.log(metric_forecast(self.bias,        \"Percent Bias\"))\n",
    "      wandb.log(metric_forecast(self.rmse,        \"Root Mean Square Error\"))\n",
    "      wandb.log(metric_forecast(self.r2_spatial,  \"Coefficient of Determination R2 - Spatial\"))\n",
    "      wandb.log(metric_forecast(self.r2_temporal, \"Coefficient of Determination R2 - Temporal\"))\n",
    "      wandb.log(metric_forecast(self.acc,         \"Accuracy\"))\n",
    "      wandb.log(metric_forecast(self.pre,         \"Precision\"))\n",
    "      wandb.log(metric_forecast(self.rec,         \"Recall\"))\n",
    "\n",
    "      # Forecast Evolution - Give an idea of the evolution of a metric accross the validation set for the best and worst forecast\n",
    "      metric_forecast_evolution(self.mae,         [[0, 1], [0, 2], [0, 4]],                \"Mean Absolute Error\")\n",
    "      metric_forecast_evolution(self.bias,        [[-100, 100], [-250, 100], [-500, 100]], \"Percent Bias\")\n",
    "      metric_forecast_evolution(self.rmse,        [[0, 1], [0, 2], [0, 4]],                \"Root Mean Square Error\")\n",
    "      metric_forecast_evolution(self.r2_spatial,  [[-25, 1.01], [-5, 1.01], [-2, 1.01]],   \"Coefficient of Determination R2 - Spatial\")\n",
    "      metric_forecast_evolution(self.r2_temporal, [[-25, 1.01], [-5, 1.01], [2, 1.01]],    \"Coefficient of Determination R2 - Temporal\")\n",
    "      metric_forecast_evolution(self.acc,         [[0, 0.25], [0, 0.5], [0, 1.01]],        \"Accuracy\")\n",
    "      metric_forecast_evolution(self.pre,         [[0, 0.25], [0, 0.5], [0, 1.01]],        \"Precision\")\n",
    "      metric_forecast_evolution(self.rec,         [[0, 0.25], [0, 0.5], [0, 1.01]],        \"Recall\")\n",
    "\n",
    "\n",
    "metrics = BlackSea_Metrics(data_oxygen = data_oxygen, mask = bs_mask_with_depth, hypoxia_treshold = 0.1, window_output = 3, number_trajectories = 20)\n",
    "metrics.analyze(pred[6:10], y[6:10])\n",
    "# metrics.send_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
